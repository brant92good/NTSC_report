\allowdisplaybreaks[4]
\section{系統架構與設計目標}
為了驗證本研究模型在真實場景中的應用潛力，本研究開發了一套即時音訊深偽偵測系統。該系統不僅提供直觀的視覺化介面，更整合了多種深度學習模型，實現從音訊輸入、特徵分析到結果判定的自動化流程。
\section{介面功能與模組說明}
本系統採用前後端分離（Decoupled Architecture）架構，以確保系統的擴充性與推論效率：
\begin{enumerate}
    \item{前端展示層 (Next.js)}
    採用 Next.js 框架構建。利用其高效的路由管理與組件化開發優勢，實現響應式網頁介面。前端負責處理音訊錄製、檔案上傳與即時波形顯示，並透過 RESTful API 與後端進行異步通訊。
    \item{後端推論層 (FastAPI \& PyTorch)}
    後端核心採用 FastAPI 框架，其異步處理能力能有效降低多模型併發推論時的延遲。模型推理部分則由 PyTorch 驅動，整合了本研究所介紹的 ASR 轉錄模型 Whisper、TTS 模型 IndexTTS2、三種深偽檢測模型 MFA-Conformer、W2V-AASIST、SpeechPrompt v2。
    \item{快速部署環境 (Docker)}
    為了應對深度學習環境中複雜的依賴關係（如特定版本的 CUDA、cuDNN、PyTorch 與 FastAPI 依賴庫），本系統全面採用 Docker 容器化技術。這不僅確保了環境的一致性，更極大化地提升了部署效率。
\end{enumerate}
\subsection{語音輸入}
系統提供兩個音訊來源管道，如圖XX左上區塊。使用者可以透過錄音按鈕進行現場錄音，亦可以透過上傳現有音訊檔案。
\subsection{音訊生成與偽造}
平台提供使用者將輸入進的音訊來源當作參考語音透過特定 TTS （如 IndexTTS2）生成偽造語音。生成參考文本可由網頁中上區塊進行輸入，亦可透過 ASR 按鈕將參考音訊透過 Whisper 轉錄成文本進行輸入。生成後的語音將顯示在右上區塊。
\subsection{偵測核心與效能呈現}
當使用者點擊檢測按鈕後，系統會將使用者輸入之音訊以及透過 TTS 生成之音訊送入模型後端進行評測。結果區域以列表方式呈現不同模型的判別數據。
\begin{enumerate}
    \item{模型標識 (Model ID)}
    列出參與評測的模型架構。
    \item{機率分佈 (Confidence Score)}
    顯示「真實 (Bonafide)」與「偽造 (Spoof)」的機率百分比。其數值由模型輸出之 Logits 經過 Softmax 轉換所得：
    \begin{equation}
    P_{i} = \frac{e^{z_i}}{\sum_{j \in \{B, S\}} e^{z_j}}
    \end{equation}
    其中 $z$ 為模型最後一層線性層輸出之原始分數 (Logits)，$i \in \{B, S\}$ 分別代表真音與偽造語音類別。
    
    \item{判定門檻 (Threshold)}
    門檻值 τ 為系統判定真偽的裁決基準。本平台允許針對不同模型設定獨立的門檻值，其設定依據各模型在開發集（Dev set）上取得等錯誤率（EER）時的決策點。若模型輸出之偽造機率 PS​>τ，系統將判定為「Spoof」並以紅色高亮顯示；反之則判定為「Bonafide」。
    
\end{enumerate}
\section{後端推論流程與模型優化}
